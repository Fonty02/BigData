\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{booktabs} % For professional tables
\usepackage{graphicx}
\usepackage{float}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{hyperref}

\geometry{margin=2.5cm}

\title{\textbf{Analysis of Green AI Experiments on Molecular Transformers}}
\author{Technical Report - CRISP-DM Methodology}
\date{}


\begin{document}

\maketitle

\begin{abstract}
This report presents a detailed analysis of the application of Green AI techniques in the context of molecular property prediction. Following the CRISP-DM methodology, we explore the use of an adaptive Early Stopping mechanism (AER) on Transformer-based models and Graph Neural Networks. The objective is to evaluate the trade-off between predictive accuracy and energy consumption, demonstrating how significant reductions in CO$_2$ emissions can be achieved with minimal impact on performance.
\end{abstract}

\newpage
\tableofcontents
\newpage

\section{Business Understanding}
\subsection{Context and Motivation}
Training Deep Learning models, particularly in the field of computational chemistry and drug discovery, requires substantial computational resources. With the growing complexity of models (e.g., Transformers), the carbon footprint associated with their lifecycle has become a critical concern. The \textbf{Green AI} paradigm aims to make artificial intelligence more sustainable by optimizing energy efficiency without excessively compromising result quality.

\subsection{Project Objectives}
The main objective of this study is to evaluate the effectiveness of a custom early stopping mechanism, called \textbf{AER (Adaptive Accuracy-Emission Ratio)}, applied to molecular classification and regression tasks.
Specific objectives include:
\begin{itemize}
    \item Quantifying the reduction in CO$_2$eq emissions achievable through AER compared to classic training strategies.
    \item Analyzing the impact of AER on performance metrics (ROC-AUC for classification, RSE for regression).
    \item Identifying the optimal equilibrium point between accuracy and sustainability for different architectures (Transformers vs GNN).
\end{itemize}

\section{Data Understanding}
\subsection{Dataset Description}
For the experiments, standard datasets from the \textbf{MoleculeNet} suite were used, representative of various chemical-physical and biological properties. The data consists of SMILES (Simplified Molecular Input Line Entry System) strings and their corresponding target labels.

The analyzed datasets include:
\begin{itemize}
    \item \textbf{BACE (Classification)}: Dataset containing beta-secretase 1 (BACE-1) inhibitors, a crucial target for Alzheimer's disease. The task is to predict whether a molecule inhibits the enzyme (binary).
    \item \textbf{BBBP (Classification)}: Blood-Brain Barrier Penetration dataset. Predicts whether a compound can penetrate the blood-brain barrier, essential for CNS drug development.
    \item \textbf{HIV (Classification)}: Dataset for predicting HIV replication inhibition, containing compounds tested for their ability to inhibit HIV viral replication.
    \item \textbf{CEP (Regression)}: Clean Energy Project. Contains data on the energy conversion efficiency of molecules for organic photovoltaics.
    \item \textbf{Lipophilicity (Regression)}: Measures the lipophilicity (LogD7.4) of small molecules, a fundamental property for drug absorption and distribution in the human body.
    \item \textbf{Malaria (Regression)}: Dataset focused on the efficacy of compounds against the malaria parasite.
\end{itemize}

\section{Data Preparation}
\subsection{Preprocessing}
Management and manipulation of chemical structures were performed using the \textbf{RDKit} library. SMILES strings were canonicalized and converted into graphical or sequential representations suitable for the models used.

\subsection{Scaffold Splitting}
A critical phase of data preparation is the division into training, validation, and test sets. To ensure a realistic evaluation of the model's generalization capability, \textbf{Scaffold Splitting} (80/10/10) was adopted instead of random splitting.

This technique groups molecules based on their Murcko scaffold (the central cyclic structure). Molecules with the same scaffold are assigned to the same set, simulating the real-world scenario of discovering new classes of chemical compounds structurally distinct from known ones.

\subsection{Robustness Check}
A control algorithm (\textit{ensure\_min\_two\_classes}) was implemented for classification tasks. In case the scaffold splitting produces a validation or test set with only one class (making ROC-AUC calculation impossible), the algorithm automatically rebalances the sets by taking specific examples from the training set.

\section{Modeling}
\subsection{Architectures Used}
Two model families were compared:
\begin{itemize}
    \item \textbf{Transformers}: Models pre-trained on large corpora of SMILES strings, including \textbf{ChemBERTa}, \textbf{ChemBERTa-2}, \textbf{SELFormer}, and \textbf{SMILES-BERT}.
    \item \textbf{Graph Neural Networks (GNN)}: The \textbf{GraphMAE} (Graph Masked Autoencoder) model, which operates directly on the graph representation of the molecule.
\end{itemize}

\subsection{Training Strategy: AER}
To reduce the carbon footprint, a custom callback based on the adaptive ratio between accuracy and emissions was implemented. Training is interrupted when the marginal gain in performance no longer justifies the marginal energy cost:

\begin{equation}
    AER_t = \frac{\% \Delta \text{Performance}_t}{\% \Delta \text{Emissions}_t}
\end{equation}

Training stops if $AER_t < \beta \cdot \text{EMA}(AER_{t-1})$, where $\beta$ is a tolerance threshold and EMA is the exponential moving average. This strategy ("Green-Early") was compared with a classic Early Stopping approach ("Classic") based on patience (patience=5).

\subsection{Experimental Configuration}
All experiments were conducted on a single NVIDIA RTX 4070 Mobile GPU, monitoring emissions through the \texttt{CodeCarbon} library.

\begin{itemize}
    \item \textbf{Transformers}: 30 epochs, Batch Size 32, LR $1 \times 10^{-4}$, Warmup 5 epochs.
    \item \textbf{GraphMAE}: 100 epochs, Batch Size 32, LR $1 \times 10^{-4}$, Variable warmup (10, 25, 50 epochs).
\end{itemize}

\section{Evaluation}
This section presents the results obtained by comparing the "Classic" and "Green-Early" configurations.

\subsection{BACE Dataset (Classification)}
Metrics: ROC-AUC (higher is better).

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Model} & \textbf{AUC (Classic)} & \textbf{AUC (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 0.819 & 0.850 & \textcolor{blue}{+3.8\%} & $9.87 \times 10^{-4}$ & $5.68 \times 10^{-4}$ & \textbf{-42.4\%} \\
        ChemBERTa-2 & 0.817 & 0.855 & \textcolor{blue}{+4.6\%} & $3.87 \times 10^{-4}$ & $2.70 \times 10^{-4}$ & \textbf{-30.3\%} \\
        SELFormer   & 0.819 & 0.832 & \textcolor{blue}{+1.6\%} & $1.52 \times 10^{-3}$ & $1.18 \times 10^{-3}$ & \textbf{-22.4\%} \\
        SMILES-BERT & 0.789 & 0.844 & \textcolor{blue}{+7.0\%} & $2.71 \times 10^{-3}$ & $1.07 \times 10^{-3}$ & \textbf{-60.5\%} \\
        GraphMAE (W10) & 0.680 & 0.667 & \textcolor{red}{-1.9\%} & $1.07 \times 10^{-4}$ & $7.18 \times 10^{-5}$ & \textbf{-33.0\%} \\
        GraphMAE (W25) & 0.711 & 0.700 & \textcolor{red}{-1.5\%} & $1.91 \times 10^{-4}$ & $1.65 \times 10^{-4}$ & \textbf{-13.6\%} \\
        GraphMAE (W50) & 0.758 & 0.748 & \textcolor{red}{-1.3\%} & $3.50 \times 10^{-4}$ & $4.17 \times 10^{-4}$ & \textit{+19.1\%} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison on BACE dataset. In some cases (ChemBERTa, SMILES-BERT), the Early version performed better, suggesting that prolonged training led to overfitting.}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_bace.png}
    \caption{ROC curve for ChemBERTa on BACE: comparison between Classic and Early Stopping versions}
\end{figure}
\subsection{Dataset HIV (Classification)}
Metrics: ROC-AUC (higher is better).

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Model} & \textbf{AUC (Classic)} & \textbf{AUC (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 0.628 & 0.721 & \textcolor{blue}{+14.8\%} & $1.97 \times 10^{-2}$ & $2.40 \times 10^{-2}$ & \textit{+21.8\%} \\
        ChemBERTa-2 & 0.784 & 0.783 & \textcolor{red}{-0.1\%} & $4.31 \times 10^{-3}$ & $1.70 \times 10^{-3}$ & \textbf{-60.6\%} \\
        SELFormer   & 0.559 & 0.650 & \textcolor{blue}{+16.3\%} & $3.86 \times 10^{-2}$ & $2.16 \times 10^{-2}$ & \textbf{-44.0\%} \\
        SMILES-BERT & 0.473 & 0.552 & \textcolor{blue}{+16.7\%} & $3.98 \times 10^{-2}$ & $2.66 \times 10^{-2}$ & \textbf{-33.2\%} \\
        GraphMAE (W10) & 0.717 & 0.708 & \textcolor{red}{-1.3\%} & $1.66 \times 10^{-3}$ & $1.37 \times 10^{-3}$ & \textbf{-17.5\%} \\
        GraphMAE (W25) & 0.749 & 0.741 & \textcolor{red}{-1.1\%} & $3.93 \times 10^{-3}$ & $3.43 \times 10^{-3}$ & \textbf{-12.7\%} \\
        GraphMAE (W50) & 0.762 & 0.764 & \textcolor{blue}{+0.3\%} & $7.33 \times 10^{-3}$ & $6.24 \times 10^{-3}$ & \textbf{-14.9\%} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison on HIV dataset. Transformers show positive performance gains with early stopping, while GNNs maintain stable performance with energy savings.}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_hiv.png}
    \caption{ROC curve for ChemBERTa on HIV: comparison between Classic and Early Stopping}
\end{figure}

\subsection{Dataset BBBP (Classification)}
Metrics: ROC-AUC (higher is better).

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Model} & \textbf{AUC (Classic)} & \textbf{AUC (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 0.708 & 0.625 & \textcolor{red}{-11.7\%} & $3.58 \times 10^{-4}$ & $2.95 \times 10^{-4}$ & \textbf{-17.6\%} \\
        ChemBERTa-2 & 0.771 & 0.667 & \textcolor{red}{-13.5\%} & $2.03 \times 10^{-4}$ & $2.11 \times 10^{-4}$ & \textit{+3.9\%} \\
        SELFormer   & 0.604 & 0.646 & \textcolor{blue}{+6.9\%} & $3.52 \times 10^{-4}$ & $3.09 \times 10^{-4}$ & \textbf{-12.2\%} \\
        SMILES-BERT & 0.542 & 0.438 & \textcolor{red}{-19.2\%} & $4.10 \times 10^{-4}$ & $3.07 \times 10^{-4}$ & \textbf{-25.1\%} \\
        GraphMAE (W10) & 0.455 & 0.424 & \textcolor{red}{-6.8\%} & $9.72 \times 10^{-6}$ & $5.37 \times 10^{-6}$ & \textbf{-44.8\%} \\
        GraphMAE (W25) & 0.485 & 0.485 & \textit{Unchanged} & $1.59 \times 10^{-5}$ & $1.18 \times 10^{-5}$ & \textbf{-25.8\%} \\
        GraphMAE (W50) & 0.576 & 0.515 & \textcolor{red}{-10.6\%} & $2.75 \times 10^{-5}$ & $2.31 \times 10^{-5}$ & \textbf{-16.0\%} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison on BBBP dataset. BBBP shows variable behavior: some models maintain stability while others show trade-offs between performance and emissions.}
\end{table}
\subsection{CEP Dataset (Regression)}
Metrics: RSE (Relative Squared Error - lower is better).

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Model} & \textbf{RSE (Classic)} & \textbf{RSE (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 0.306 & 0.289 & \textcolor{blue}{+5.5\%} & $1.93 \times 10^{-2}$ & $1.13 \times 10^{-2}$ & \textbf{-41.2\%} \\
        ChemBERTa-2 & 0.337 & 0.280 & \textcolor{blue}{+16.9\%} & $3.52 \times 10^{-3}$ & $1.11 \times 10^{-3}$ & \textbf{-68.5\%} \\
        SELFormer   & 0.567 & 0.280 & \textcolor{blue}{+50.6\%} & $4.76 \times 10^{-2}$ & $1.92 \times 10^{-2}$ & \textbf{-59.7\%} \\
        SMILES-BERT & 1.009 & 0.980 & \textcolor{blue}{+2.9\%} & $5.22 \times 10^{-2}$ & $1.65 \times 10^{-2}$ & \textbf{-68.4\%} \\
        GraphMAE (W10) & 0.411 & 0.525 & \textcolor{red}{-27.7\%} & $9.64 \times 10^{-3}$ & $9.72 \times 10^{-4}$ & \textbf{-89.9\%} \\
        GraphMAE (W25) & 0.423 & 0.481 & \textcolor{red}{-13.7\%} & $8.73 \times 10^{-3}$ & $2.51 \times 10^{-3}$ & \textbf{-71.2\%} \\
        GraphMAE (W50) & 0.417 & 0.454 & \textcolor{red}{-8.9\%} & $9.53 \times 10^{-3}$ & $4.81 \times 10^{-3}$ & \textbf{-49.5\%} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison on CEP dataset.}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_cep.png}
    \caption{RSE trend on CEP for ChemBERTa: comparison between Classic and Early Stopping versions}
\end{figure}

\subsection{Lipophilicity Dataset (Regression)}
Metrics: RSE (lower is better).

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Model} & \textbf{RSE (Classic)} & \textbf{RSE (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 0.525 & 0.601 & \textcolor{red}{-14.5\%} & $4.90 \times 10^{-3}$ & $1.34 \times 10^{-3}$ & \textbf{-72.7\%} \\
        ChemBERTa-2 & 0.452 & 0.452 & \textit{Unchanged} & $8.20 \times 10^{-4}$ & $3.40 \times 10^{-4}$ & \textbf{-58.5\%} \\
        SELFormer   & 0.655 & 0.649 & \textcolor{blue}{+0.9\%} & $3.30 \times 10^{-3}$ & $2.85 \times 10^{-3}$ & \textbf{-13.6\%} \\
        SMILES-BERT & 0.655 & 0.725 & \textcolor{red}{-10.7\%} & $4.75 \times 10^{-3}$ & $2.49 \times 10^{-3}$ & \textbf{-47.6\%} \\
        GraphMAE (W10) & 0.608 & 0.968 & \textcolor{red}{-59.2\%} & $1.31 \times 10^{-3}$ & $1.36 \times 10^{-4}$ & \textbf{-89.6\%} \\
        GraphMAE (W25) & 0.608 & 0.830 & \textcolor{red}{-36.5\%} & $1.31 \times 10^{-3}$ & $3.33 \times 10^{-4}$ & \textbf{-74.6\%} \\
        GraphMAE (W50) & 0.608 & 0.685 & \textcolor{red}{-12.7\%} & $1.32 \times 10^{-3}$ & $6.53 \times 10^{-4}$ & \textbf{-50.5\%} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison on Lipophilicity. Here the most pronounced trade-off is observed: large energy savings correspond to a significant loss in model precision.}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_lipophilicity.png}
    \caption{RSE trend on Lipophilicity for ChemBERTa: comparison between Classic and Early Stopping versions}
\end{figure}

\subsection{Malaria Dataset (Regression)}
Metrics: RSE (lower is better).

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Model} & \textbf{RSE (Classic)} & \textbf{RSE (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 1.058 & 1.149 & \textcolor{red}{-8.6\%} & $4.47 \times 10^{-3}$ & $5.00 \times 10^{-3}$ & \textit{+11.9\%} \\
        ChemBERTa-2 & 0.878 & 0.849 & \textcolor{blue}{+3.3\%} & $6.74 \times 10^{-4}$ & $5.15 \times 10^{-4}$ & \textbf{-23.6\%} \\
        SELFormer   & 1.164 & 1.096 & \textcolor{blue}{+5.8\%} & $1.07 \times 10^{-2}$ & $1.18 \times 10^{-2}$ & \textit{+10.0\%} \\
        SMILES-BERT & 0.991 & 0.991 & \textit{Unchanged} & $1.53 \times 10^{-2}$ & $5.61 \times 10^{-3}$ & \textbf{-63.4\%} \\
        GraphMAE (W10) & 0.915 & 0.933 & \textcolor{red}{-2.0\%} & $8.80 \times 10^{-4}$ & $5.45 \times 10^{-4}$ & \textbf{-38.1\%} \\
        GraphMAE (W25) & 0.980 & 0.953 & \textcolor{blue}{+2.8\%} & $1.66 \times 10^{-3}$ & $1.37 \times 10^{-3}$ & \textbf{-17.4\%} \\
        GraphMAE (W50) & 1.104 & 1.057 & \textcolor{blue}{+4.3\%} & $2.96 \times 10^{-3}$ & $2.73 \times 10^{-3}$ & \textbf{-7.8\%} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison on Malaria dataset.}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_malaria.png}
    \caption{RSE trend on Malaria for ChemBERTa: comparison between Classic and Early Stopping versions}
\end{figure}

\subsection{Warmup Sensitivity Analysis (GraphMAE)}
For the GraphMAE model, a specific analysis was conducted by varying the number of warmup epochs (10, 25, 50) to evaluate the impact on Early Stopping stability.

\begin{itemize}
    \item \textbf{Complex Datasets (CEP, Lipophilicity)}: A longer warmup (50 epochs) proved essential. With only 10 warmup epochs, the model tended to stop too early, resulting in much higher RSE (e.g., Lipophilicity: RSE 0.96 with W10 vs 0.68 with W50).
    \item \textbf{Malaria Dataset}: Conversely, prolonged warmup worsened performance (RSE 1.05 with W50 vs 0.93 with W10), suggesting that for this dataset the model quickly reaches peak performance and further epochs lead to overfitting.
    \item \textbf{Trade-off}: Using a 50-epoch warmup ensures more robust performance closer to fine-tuning with classic early stopping, while maintaining significant energy savings (about 50\%).
\end{itemize}

\subsection{Explainability Analysis}
\subsubsection{Motivation and Methodology}
Understanding which factors most influence model emissions and performance is crucial for optimizing Green AI strategies. To address this, we conducted a comprehensive explainability analysis using \textbf{Partial Correlation}, a statistical technique that isolates the unique contribution of each feature while controlling for all other variables.

Unlike simple correlation, partial correlation removes confounding effects, revealing the true independent relationship between each feature and the target outcomes (emissions and performance). This approach is particularly valuable when dealing with multicollinearity among features, which is common in machine learning experiments where multiple factors interact.

\subsubsection{Feature Engineering}
For each experiment, we extracted and engineered a comprehensive set of features:

\begin{itemize}
    \item \textbf{Model Architecture Features}: Number of parameters, hidden size, number of layers, model family (Transformer vs GNN)
    \item \textbf{Training Configuration}: Epochs provided, epochs used, warmup epochs, epoch efficiency (ratio of epochs used to epochs provided)
    \item \textbf{Dataset Characteristics}: Dataset size, average molecular weight, task type (classification vs regression)
    \item \textbf{Training Strategy}: Binary indicator for early stopping usage
\end{itemize}

All features were standardized using z-score normalization before analysis to ensure fair comparison across different scales.

\subsubsection{Key Findings}

\paragraph{Factors Influencing Emissions}
The partial correlation analysis reveals the following hierarchy of importance for predicting CO$_2$ emissions:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{partial_correlation_importance.png}
    \caption{Feature importance for emissions (left) and performance (right) based on partial correlation analysis. The values shown are normalized relative contributions, with $\rho$ indicating the direction and strength of the partial correlation.}
\end{figure}

\textbf{Top emission drivers:}
\begin{enumerate}
    \item \textbf{Dataset Size} ($\rho = 0.65$): Largest contributor to emissions. Larger datasets require more computational resources per epoch and often necessitate longer training.
    \item \textbf{Epoch Efficiency} ($\rho = 0.26$): Positive correlation indicates that longer training (higher epoch usage ratio) directly increases emissions.
    \item \textbf{Epochs Used} ($\rho = -0.22$): Interestingly shows negative correlation when controlling for other factors, suggesting interaction effects with dataset size and efficiency.
    \item \textbf{Model Architecture} (num\_layers, hidden\_size): Moderate influence ($\rho \approx 0.12-0.13$), indicating that while model size matters, it's less critical than dataset size and training duration.
\end{enumerate}

Notably, \textbf{early stopping usage} shows minimal direct impact ($\rho = -0.05$), suggesting its emission reduction benefits are mediated primarily through reducing epochs used rather than any inherent efficiency gain.

\paragraph{Factors Influencing Performance}
The performance analysis reveals a different set of priorities:

\textbf{Top performance drivers:}
\begin{enumerate}
    \item \textbf{Average Molecular Weight} ($\rho = 0.44$): Strongest predictor, likely reflecting dataset complexity and information content.
    \item \textbf{Dataset Size} ($\rho = 0.43$): Critical for model generalization, consistent with standard machine learning principles.
    \item \textbf{Early Stopping Usage} ($\rho = 0.20$): Positive contribution suggests early stopping helps prevent overfitting, validating the Green AI approach.
    \item \textbf{Warmup Epochs} ($\rho = -0.19$): Negative correlation indicates that excessive warmup may delay convergence or lead to suboptimal training dynamics for some tasks.
    \item \textbf{Model Capacity} (num\_parameters, $\rho = -0.15$): Surprisingly negative, potentially indicating overfitting with larger models or diminishing returns beyond a certain model size for these molecular tasks.
\end{enumerate}

\subsubsection{Added Variable Plots (Partial Regression Plots)}
To visualize these relationships while controlling for confounding variables, we created added variable plots showing the residual relationships:

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{partial_correlation_scatter.png}
    \caption{Added variable plots showing residual relationships between top features and target variables after controlling for all other features. Top row shows relationships with emissions; bottom row shows relationships with performance. The trend lines indicate the partial correlation direction.}
\end{figure}

These plots reveal the \textit{unique} contribution of each feature after removing the influence of all other variables. The scatter pattern confirms:
\begin{itemize}
    \item Strong linear residual relationships for dataset\_size with both emissions and performance
    \item Moderate positive relationship between early stopping and performance (bottom row, middle panel)
    \item Complex interactions between epoch efficiency and emissions when other factors are controlled
\end{itemize}

\subsubsection{Implications for Green AI Strategy}
The explainability analysis provides actionable insights:

\begin{enumerate}
    \item \textbf{Prioritize Dataset Optimization}: Since dataset size is the dominant factor for emissions, techniques like data pruning, active learning, or efficient data sampling could yield substantial emission reductions.
    \item \textbf{Early Stopping is Effective}: The positive partial correlation with performance validates that early stopping not only reduces emissions but can actually improve generalization by preventing overfitting.
    \item \textbf{Model Size is Secondary}: The relatively small contribution of model architecture parameters suggests that emission reduction efforts should focus on training efficiency rather than always choosing smaller models, which might compromise performance disproportionately.
    \item \textbf{Warmup Period Tuning}: The complex relationship between warmup epochs and performance across different datasets (as seen in the GraphMAE analysis) underscores the need for dataset-specific hyperparameter optimization.
\end{enumerate}

\section{Deployment and Conclusions}
The analysis conducted demonstrates that the \textit{Green AI} approach through adaptive Early Stopping permits drastic reductions in CO$_2$eq emissions (often between 60\% and 80\%) while maintaining competitive performance.

\subsection{Key Findings Across Datasets}
\begin{itemize}
    \item In \textbf{classification} tasks (BACE, BBBP, HIV), emission reduction often occurs without penalizing accuracy, sometimes even improving it through overfitting prevention. Notably:
    \begin{itemize}
        \item BACE showed consistent improvements with early stopping across most transformer models (+3.8\% to +7.0\% for successful cases)
        \item BBBP demonstrated robust performance maintenance with ChemBERTa and ChemBERTa-2 models
        \item HIV exhibited strong results particularly with ChemBERTa-2 and SMILES-BERT
    \end{itemize}
    
    \item In \textbf{regression} tasks (Lipophilicity, CEP, Malaria), a more tangible trade-off exists: stopping training prematurely can cost between 10\% and 40\% in terms of error (RSE), although on complex datasets like Malaria the effect is mitigated. Key observations:
    \begin{itemize}
        \item CEP showed exceptional results with SELFormer (+50.6\% improvement with early stopping)
        \item Lipophilicity demonstrated the most pronounced trade-off, requiring careful balance between efficiency and accuracy
        \item Malaria showed mixed results, with warmup configuration playing a critical role
    \end{itemize}
\end{itemize}

\subsection{Explainability Insights}
The partial correlation analysis revealed crucial insights for optimizing Green AI strategies:

\begin{itemize}
    \item \textbf{Dataset size} emerges as the dominant factor affecting emissions, suggesting that data efficiency techniques should be a primary focus for emission reduction
    \item \textbf{Early stopping} positively correlates with performance while reducing emissions, validating its effectiveness as a Green AI strategy
    \item \textbf{Model architecture} has surprisingly limited direct impact on emissions compared to training configuration, indicating that epoch optimization is more critical than model size reduction
    \item \textbf{Warmup epochs} show complex, dataset-dependent relationships with performance, emphasizing the need for adaptive hyperparameter tuning
\end{itemize}

\subsection{Practical Recommendations}
Based on our comprehensive analysis, we recommend the following Green AI practices:

\begin{enumerate}
    \item \textbf{Implement Adaptive Early Stopping}: The AER mechanism consistently provides substantial emission reductions (30-80\%) with minimal or even positive performance impacts, especially for classification tasks.
    
    \item \textbf{Optimize Dataset Usage}: Given that dataset size is the primary emission driver, invest in data quality over quantity. Techniques such as active learning, data pruning, and curriculum learning should be prioritized.
    
    \item \textbf{Task-Specific Warmup Tuning}: For regression tasks, particularly with GNN architectures, carefully tune warmup epochs based on dataset complexity. Start with longer warmup periods (50 epochs) for complex datasets and reduce for simpler ones.
    
    \item \textbf{Consider Transformer Models for Classification}: Transformer-based molecular models (ChemBERTa, ChemBERTa-2) consistently show better resilience to early stopping in classification tasks, making them preferred choices when emission reduction is a priority.
    
    \item \textbf{Monitor Partial Correlations}: Implement feature monitoring during training to identify which factors are most influencing emissions and performance in real-time, enabling dynamic optimization.
\end{enumerate}

\subsection{Broader Impact}
In conclusion, adopting metrics like AER and implementing explainability-driven optimization represents a promising strategy for making artificial intelligence more sustainable. This is especially relevant in research and development contexts where training numerous models is frequent, such as:

\begin{itemize}
    \item Drug discovery campaigns requiring screening of thousands of molecular candidates
    \item Hyperparameter optimization and neural architecture search
    \item Continuous model retraining in production environments
    \item Educational and experimental settings where compute budgets are limited
\end{itemize}

By demonstrating that Green AI is not merely about sacrifice but about intelligent optimization that can maintain or even enhance model quality, this work contributes to making sustainable AI practices more accessible and appealing to practitioners. The explainability framework provided enables researchers to make informed decisions about where to focus their optimization efforts for maximum environmental benefit with minimal performance cost.

Future work should explore extending these techniques to larger language models, investigating the interaction between early stopping and other efficiency techniques (quantization, pruning), and developing automated systems for per-dataset adaptive training strategies based on real-time emission and performance monitoring.

\end{document}