\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{booktabs} % Per tabelle professionali
\usepackage{graphicx}
\usepackage{float}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{caption}

\geometry{margin=2.5cm}

\title{\textbf{Analisi degli Esperimenti di Green AI su Molecular Transformers}}
\author{Report Tecnico}
\date{\today}

\begin{document}

\maketitle

\section{Metodologia e Gestione dei Dati}

\subsection{Preprocessing e Scaffold Splitting}
La gestione dei dataset chimici è stata effettuata utilizzando la libreria RDKit. Una fase critica del processo è la suddivisione dei dati in set di training, validazione e test. Invece di una suddivisione casuale, è stato implementato lo \textbf{Scaffold Splitting} (80/10/10).

Questa tecnica raggruppa le molecole in base al loro scafold di Murcko (la struttura centrale ciclica). Le molecole con lo stesso scaffold vengono assegnate allo stesso set. Ciò garantisce una valutazione più realistica della capacità di generalizzazione del modello, simulando la scoperta di nuove strutture chimiche distinte da quelle note. 

L'algoritmo implementato include inoltre un controllo di robustezza (\textit{ensure\_min\_two\_classes}): nel caso in cui la suddivisione per scaffold produca un set di validazione o test con una sola classe (rendendo impossibile il calcolo della ROC-AUC), l'algoritmo ribilancia i set prelevando esempi specifici dal training set.

\subsection{Meccanismo di Early Stopping (AER)}
Per ridurre l'impronta di carbonio, è stato implementato un callback personalizzato basato sul rapporto adattivo tra accuratezza ed emissioni (AER - Adaptive Accuracy-Emission Ratio). Il training viene interrotto quando il guadagno marginale in performance non giustifica più il costo energetico marginale:

\begin{equation}
    AER_t = \frac{\% \Delta \text{Performance}_t}{\% \Delta \text{Emissioni}_t}
\end{equation}

Il training si arresta se $AER_t < \beta \cdot \text{EMA}(AER_{t-1})$, dove $\beta$ è una soglia di tolleranza e EMA è la media mobile esponenziale.

\section{Configurazione Sperimentale}
Tutti gli esperimenti sono stati condotti su una singola GPU NVIDIA RTX 4070 Mobile monitorando le emissioni tramite \texttt{CodeCarbon}.

\subsection{Parametri di Training}
\begin{itemize}
    \item \textbf{Modelli basati su Transformers} (ChemBERTa, ChemBERTa-2, SELFormer, SMILES-BERT):
    \begin{itemize}
        \item \textbf{Epoche}: 30
        \item \textbf{Batch Size}: 32
        \item \textbf{Learning Rate}: $1 \times 10^{-4}$
        \item \textbf{Optimizer}: Adam
        \item \textbf{Warmup (Early Stopping)}: 5 epoche
    \end{itemize}
    \item \textbf{GraphMAE} (Graph Neural Network):
    \begin{itemize}
        \item \textbf{Epoche}: 100 (necessarie per la convergenza delle GNN)
        \item \textbf{Batch Size}: 32
        \item \textbf{Learning Rate}: $1 \times 10^{-4}$
        \item \textbf{Optimizer}: Adam (Weight Decay = 0)
        \item \textbf{Warmup (Early Stopping)}: Variabile (10, 25, 50 epoche) per analizzare la stabilità.
    \end{itemize}
\end{itemize}

\section{Risultati Sperimentali}

Di seguito vengono presentati i risultati per i quattro dataset analizzati. I modelli sono stati testati in configurazione "Classic" (early stopping classico con patience=5) e "Green-Early" (con arresto anticipato basato su emissioni).

\subsection{Dataset BACE (Classificazione)}
Metriche utilizzate: ROC-AUC (maggiore è meglio).
\vspace{0.3cm}

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Modello} & \textbf{AUC (Classic)} & \textbf{AUC (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 0.819 & 0.850 & \textcolor{blue}{+3.8\%} & $9.87 \times 10^{-4}$ & $5.68 \times 10^{-4}$ & \textbf{-42.4\%} \\
        ChemBERTa-2 & 0.817 & 0.855 & \textcolor{blue}{+4.6\%} & $3.87 \times 10^{-4}$ & $2.70 \times 10^{-4}$ & \textbf{-30.3\%} \\
        SELFormer   & 0.819 & 0.832 & \textcolor{blue}{+1.6\%} & $1.52 \times 10^{-3}$ & $1.18 \times 10^{-3}$ & \textbf{-22.4\%} \\
        SMILES-BERT & 0.789 & 0.844 & \textcolor{blue}{+7.0\%} & $2.71 \times 10^{-3}$ & $1.07 \times 10^{-3}$ & \textbf{-60.5\%} \\
        GraphMAE (W10) & 0.680 & 0.667 & \textcolor{red}{-1.9\%} & $1.07 \times 10^{-4}$ & $7.18 \times 10^{-5}$ & \textbf{-33.0\%} \\
        GraphMAE (W25) & 0.711 & 0.700 & \textcolor{red}{-1.5\%} & $1.91 \times 10^{-4}$ & $1.65 \times 10^{-4}$ & \textbf{-13.6\%} \\
        GraphMAE (W50) & 0.758 & 0.748 & \textcolor{red}{-1.3\%} & $3.50 \times 10^{-4}$ & $4.17 \times 10^{-4}$ & \textit{+19.1\%} \\
        \bottomrule
    \end{tabular}
    \caption{Confronto su dataset BACE. In alcuni casi (ChemBERTa, SMILES-BERT), la versione Early ha performato meglio, suggerendo che il training prolungato portava ad overfitting.}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_bace.png}
    \caption{Curva ROC per ChemBERTa su BACE: confronto tra versione Classic ed Early Stopping}
\end{figure}

\subsection{Dataset CEP (Regressione)}
Metriche utilizzate: RSE (Relative Squared Error - minore è meglio). 
\vspace{0.3cm}

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Modello} & \textbf{RSE (Classic)} & \textbf{RSE (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 0.306 & 0.289 & \textcolor{blue}{+5.5\%} & $1.93 \times 10^{-2}$ & $1.13 \times 10^{-2}$ & \textbf{-41.2\%} \\
        ChemBERTa-2 & 0.337 & 0.280 & \textcolor{blue}{+16.9\%} & $3.52 \times 10^{-3}$ & $1.11 \times 10^{-3}$ & \textbf{-68.5\%} \\
        SELFormer   & 0.567 & 0.280 & \textcolor{blue}{+50.6\%} & $4.76 \times 10^{-2}$ & $1.92 \times 10^{-2}$ & \textbf{-59.7\%} \\
        SMILES-BERT & 1.009 & 0.980 & \textcolor{blue}{+2.9\%} & $5.22 \times 10^{-2}$ & $1.65 \times 10^{-2}$ & \textbf{-68.4\%} \\
        GraphMAE (W10) & 0.411 & 0.525 & \textcolor{red}{-27.7\%} & $9.64 \times 10^{-3}$ & $9.72 \times 10^{-4}$ & \textbf{-89.9\%} \\
        GraphMAE (W25) & 0.423 & 0.481 & \textcolor{red}{-13.7\%} & $8.73 \times 10^{-3}$ & $2.51 \times 10^{-3}$ & \textbf{-71.2\%} \\
        GraphMAE (W50) & 0.417 & 0.454 & \textcolor{red}{-8.9\%} & $9.53 \times 10^{-3}$ & $4.81 \times 10^{-3}$ & \textbf{-49.5\%} \\
        \bottomrule
    \end{tabular}
    \caption{Confronto su dataset CEP. Nota: Per RSE, un valore più basso indica una performance migliore.}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_cep.png}
    \caption{Andamento del RSE su CEP per ChemBERTa: confronto tra versione Classic ed Early Stopping}
\end{figure}

\subsection{Dataset Lipophilicity (Regressione)}
Metriche utilizzate: RSE (minore è meglio).
\vspace{0.3cm}

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Modello} & \textbf{RSE (Classic)} & \textbf{RSE (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 0.525 & 0.601 & \textcolor{red}{-14.5\%} & $4.90 \times 10^{-3}$ & $1.34 \times 10^{-3}$ & \textbf{-72.7\%} \\
        ChemBERTa-2 & 0.452 & 0.452 & \textit{Invar.} & $8.20 \times 10^{-4}$ & $3.40 \times 10^{-4}$ & \textbf{-58.5\%} \\
        SELFormer   & 0.655 & 0.649 & \textcolor{blue}{+0.9\%} & $3.30 \times 10^{-3}$ & $2.85 \times 10^{-3}$ & \textbf{-13.6\%} \\
        SMILES-BERT & 0.655 & 0.725 & \textcolor{red}{-10.7\%} & $4.75 \times 10^{-3}$ & $2.49 \times 10^{-3}$ & \textbf{-47.6\%} \\
        GraphMAE (W10) & 0.608 & 0.968 & \textcolor{red}{-59.2\%} & $1.31 \times 10^{-3}$ & $1.36 \times 10^{-4}$ & \textbf{-89.6\%} \\
        GraphMAE (W25) & 0.608 & 0.830 & \textcolor{red}{-36.5\%} & $1.31 \times 10^{-3}$ & $3.33 \times 10^{-4}$ & \textbf{-74.6\%} \\
        GraphMAE (W50) & 0.608 & 0.685 & \textcolor{red}{-12.7\%} & $1.32 \times 10^{-3}$ & $6.53 \times 10^{-4}$ & \textbf{-50.5\%} \\
        \bottomrule
    \end{tabular}
    \caption{Confronto su Lipophilicity. Qui si nota il trade-off più marcato: grandi risparmi energetici corrispondono a una perdita significativa di precisione nel modello.}
\end{table}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_lipophilicity.png}
    \caption{Andamento del RSE su Lipophilicity per ChemBERTa: confronto tra versione Classic ed Early Stopping}
\end{figure}


\subsection{Dataset Malaria (Regressione)}
Metriche utilizzate: RSE (minore è meglio).
\vspace{0.3cm}

\begin{table}[H]
    \centering
    \tiny
    \begin{tabular}{lcccccc}
        \toprule
        \textbf{Modello} & \textbf{RSE (Classic)} & \textbf{RSE (Early)} & \textbf{$\Delta$ Perf.} & \textbf{CO$_2$eq (kg) C.} & \textbf{CO$_2$eq (kg) E.} & \textbf{$\Delta$ Emiss.} \\
        \midrule
        ChemBERTa   & 1.058 & 1.149 & \textcolor{red}{-8.6\%} & $4.47 \times 10^{-3}$ & $5.00 \times 10^{-3}$ & \textit{+11.9\%} \\
        ChemBERTa-2 & 0.878 & 0.849 & \textcolor{blue}{+3.3\%} & $6.74 \times 10^{-4}$ & $5.15 \times 10^{-4}$ & \textbf{-23.6\%} \\
        SELFormer   & 1.164 & 1.096 & \textcolor{blue}{+5.8\%} & $1.07 \times 10^{-2}$ & $1.18 \times 10^{-2}$ & \textit{+10.0\%} \\
        SMILES-BERT & 0.991 & 0.991 & \textit{Invar.} & $1.53 \times 10^{-2}$ & $5.61 \times 10^{-3}$ & \textbf{-63.4\%} \\
        GraphMAE (W10) & 0.915 & 0.933 & \textcolor{red}{-2.0\%} & $8.80 \times 10^{-4}$ & $5.45 \times 10^{-4}$ & \textbf{-38.1\%} \\
        GraphMAE (W25) & 0.980 & 0.953 & \textcolor{blue}{+2.8\%} & $1.66 \times 10^{-3}$ & $1.37 \times 10^{-3}$ & \textbf{-17.4\%} \\
        GraphMAE (W50) & 1.104 & 1.057 & \textcolor{blue}{+4.3\%} & $2.96 \times 10^{-3}$ & $2.73 \times 10^{-3}$ & \textbf{-7.8\%} \\
        \bottomrule
    \end{tabular}
    \caption{Confronto su Malaria. In questo dataset, l'Early Stopping ha spesso migliorato o mantenuto invariate le performance (RSE più basso o simile), suggerendo che i modelli tendono a saturare o overfittare rapidamente su questi dati.}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{tradeoff_experiments_malaria.png}
    \caption{Andamento del RSE su Malaria per ChemBERTa: confronto tra versione Classic ed Early Stopping}
\end{figure}

\subsection{Analisi Sensibilità Warmup (GraphMAE)}
Per il modello GraphMAE, è stata condotta un'analisi specifica variando il numero di epoche di warmup (10, 25, 50) per valutare l'impatto sulla stabilità dell'Early Stopping.

\begin{itemize}
    \item \textbf{Dataset Complessi (CEP, Lipophilicity)}: Un warmup più lungo (50 epoche) si è rivelato fondamentale. Con soli 10 epoche di warmup, il modello tendeva a fermarsi troppo presto, risultando in un RSE molto più alto (es. Lipophilicity: RSE 0.96 con W10 vs 0.68 con W50).
    \item \textbf{Dataset Malaria}: Al contrario, un warmup prolungato ha peggiorato le performance (RSE 1.05 con W50 vs 0.93 con W10), suggerendo che per questo dataset il modello raggiunge rapidamente il picco di performance e ulteriori epoche portano a overfitting.
    \item \textbf{Trade-off}: L'uso di un warmup di 50 epoche garantisce prestazioni più robuste e vicine al fine-tuning con early-stopping classico, pur mantenendo un risparmio energetico significativo (circa 50\%).
\end{itemize}

\section{Conclusioni}
L'analisi dimostra che l'approccio \textit{Green AI} tramite Early Stopping adattivo permette di ridurre drasticamente le emissioni di CO$_2$eq (spesso tra il 60\% e l'80\%). 

\begin{itemize}
    \item Nei task di \textbf{classificazione} (BACE), la riduzione delle emissioni avviene senza penalizzare l'accuratezza, anzi talvolta migliorandola grazie alla prevenzione dell'overfitting.
    \item Nei task di \textbf{regressione} (Lipophilicity, CEP), esiste un trade-off più tangibile: interrompere il training prematuramente può costare tra il 10\% e il 40\% in termini di errore (RSE), sebbene su dataset complessi come Malaria l'effetto sia mitigato.
\end{itemize}

\end{document}