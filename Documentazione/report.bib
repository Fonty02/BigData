@article{Attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{EMARecSys,
  title        = {\textit{While My RecSys Gently Weeps}: Energy-Efficient Early Stopping with Exponential Weighted Moving Average for Green Recommender Systems},
  author       = {Spillo, Giuseppe and De Filippo, Allegra and Monopoli, Vincenzo and Musto, Cataldo and Milano, Michela and Semeraro, Giovanni},
  journal      = {ACM Transactions on Information Systems, \textit{Under Review}},
  year         = {2025}
}


@article{GreenAI,
  title={Green AI},
  author={Schwartz, Roy and Dodge, Jesse and Smith, Noah A and Etzioni, Oren},
  journal={Communications of the ACM},
  volume={63},
  number={12},
  pages={54--63},
  year={2020},
  publisher={ACM New York, NY, USA},
  note={Available also as arXiv:1907.10597}
}

@article{GNN_Scarselli,
  title={The graph neural network model},
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE Transactions on Neural Networks},
  volume={20},
  number={1},
  pages={61--80},
  year={2009},
  publisher={IEEE}
}



@article{CodeCarbon,
  title={Quantifying the carbon emissions of machine learning},
  author={Lacoste, Alexandre and Luccioni, Alexandra and Schmidt, Victor and Dandres, Thomas},
  journal={arXiv preprint arXiv:1910.09700},
  year={2019},
  url={https://arxiv.org/abs/1910.09700}
}


@inproceedings{Fonty,
author = {Spillo, Giuseppe and De Filippo, Allegra and Fontana, Emanuele and Milano, Michela and Semeraro, Giovanni},
title = {Training Green and Sustainable Recommendation Models: Introducing Carbon Footprint Data into Early Stopping Criteria},
year = {2025},
isbn = {9798400713132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699682.3728336},
doi = {10.1145/3699682.3728336},
abstract = {With the growing focus on Green AI, there is an urgent need for algorithms that are designed to minimize their environmental impact while maintaining satisfying performance. In this paper, we introduce a novel early stopping strategy that considers carbon footprint data while training a recommendation algorithm. In particular, during the training phase, our criterion epoch-by-epoch analyzes the improvement in terms of predictive accuracy and compares it to the increase in carbon emissions. Then, we analyze the trade-off between the scores, and when the accuracy improves at a rate that is not favorable, the training is stopped.In the experimental evaluation, we showed that our strategy could significantly reduce the carbon footprint of several state-of-the-art recommendation models, with a limited decrease in accuracy and fairness. While more work is needed to automatically balance the trade-off between accuracy and emissions, this paper sheds light on the need for more sustainable recommendation models and takes a significant step toward designing green training strategies.},
booktitle = {Proceedings of the 33rd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {341–346},
numpages = {6},
keywords = {Sustainability, Recommender Systems, Green AI, Carbon Footprint},
location = {
},
series = {UMAP '25}
}

@article{MoleculeNet,
  title={MoleculeNet: a benchmark for molecular machine learning},
  author={Wu, Zhenqin and Ramsundar, Bharath and Feinberg, Evan N and Gomes, Joseph and Geniesse, Caleb and Pappu, Aneesh S and Leswing, Karl and Pande, Vijay},
  journal={Chemical science},
  volume={9},
  number={2},
  pages={513--530},
  year={2018},
  publisher={Royal Society of Chemistry}
}


@misc{ChemBERTa,
  title={ChemBERTa-zinc-base-v1},
  publisher={Hugging Face},
  howpublished={\url{https://huggingface.co/seyonec/ChemBERTa-zinc-base-v1}},
}

@misc{ChemBERTa2,
  title={ChemBERTa-2},
  publisher={Hugging Face},
  howpublished={\url{https://huggingface.co/DeepChem/ChemBERTa-77M-MLM}},
}


@misc{SELFormer,
      title={SELFormer: Molecular Representation Learning via SELFIES Language Models}, 
      author={Atakan Yüksel and Erva Ulusoy and Atabey Ünlü and Gamze Deniz and Tunca Doğan},
      year={2023},
      eprint={2304.04662},
      archivePrefix={arXiv},
      primaryClass={q-bio.QM}
}

@misc{SMILESBERT,
  title={SMILES-BERT},
  publisher={Hugging Face},
  howpublished={\url{https://huggingface.co/JuIm/SMILES_BERT}},
}


@inproceedings{GraphMAE,
  title={Graphmae: Self-supervised masked graph autoencoders},
  author={Hou, Zhenyu and Liu, Xiao and Cen, Yukuo and Dong, Yuxiao and Yang, Hongxia and Wang, Chunjie and Tang, Jie},
  booktitle={Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining},
  pages={594--604},
  year={2022}
}


@misc{UN2030,
  title={Transforming our world: the 2030 Agenda for Sustainable Development},
  author={{United Nations}},
  year={2015},
  publisher={United Nations},
  url={https://sdgs.un.org/2030agenda},
  note={Resolution adopted by the General Assembly on 25 September 2015}
}